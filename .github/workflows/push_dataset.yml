name: Generate and Push Dataset

on:
  workflow_dispatch:
  push:
    branches:
      - main
  workflow_run:
    workflows: ["EDINET XBRL Download"]
    types:
      - completed

jobs:
  build-and-push:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      actions: read

    steps:
      # 1️⃣ parser repo checkout
      - name: Checkout parser repository
        uses: actions/checkout@v4

      # 2️⃣ Python setup
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # 3️⃣ Install dependencies
      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      # 4️⃣ Ensure data directory structure exists
      - name: Ensure data directory structure
        if: github.event_name == 'workflow_run'
        run: |
          # アーティファクトダウンロード前にディレクトリ構造を確保
          mkdir -p data/edinet/raw_xbrl
          mkdir -p data/edinet/raw_zip
          echo "Data directory structure created"

      # 4.5️⃣ Download XBRL artifacts from edinet-download workflow
      - name: Download XBRL data artifacts
        if: github.event_name == 'workflow_run'
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: edinet-data
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ github.event.workflow_run.id }}
          path: data/

      # 4.6️⃣ Verify downloaded artifacts
      - name: Verify downloaded artifacts
        if: github.event_name == 'workflow_run'
        run: |
          echo "Checking data directory structure..."
          echo "Current directory: $(pwd)"
          echo "Directory contents:"
          ls -la || true
          if [ -d "data" ]; then
            echo "✓ data/ directory exists"
            echo "data/ contents:"
            ls -la data/ || true
            if [ -d "data/edinet" ]; then
              echo "✓ data/edinet/ directory exists"
              echo "data/edinet/ contents:"
              ls -la data/edinet/ || true
              if [ -d "data/edinet/raw_xbrl" ]; then
                echo "✓ data/edinet/raw_xbrl/ directory exists"
                echo "XBRL files found:"
                find data/edinet/raw_xbrl/ -name "*.xbrl" | head -10 || echo "No XBRL files found"
                echo "Total XBRL files: $(find data/edinet/raw_xbrl/ -name '*.xbrl' 2>/dev/null | wc -l)"
              else
                echo "✗ WARNING: data/edinet/raw_xbrl/ directory does not exist"
                echo "Checking if data/edinet/raw_xbrl exists as file:"
                ls -la data/edinet/raw_xbrl 2>&1 || true
              fi
            else
              echo "✗ WARNING: data/edinet/ directory does not exist"
              echo "Checking if data/edinet exists as file:"
              ls -la data/edinet 2>&1 || true
            fi
          else
            echo "✗ WARNING: data/ directory does not exist - artifacts may not have been downloaded"
            echo "Checking for artifact download errors..."
          fi

      # 5️⃣ SSH設定（Deploy Key）
      - name: Setup SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.DATASET_DEPLOY_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan github.com >> ~/.ssh/known_hosts

      # 6️⃣ financial-dataset clone
      - name: Clone dataset repository
        run: |
          git clone git@github.com:yuukisabu0310/financial-dataset.git dataset

      # 7️⃣ DATASET_PATH 環境変数
      - name: Set DATASET_PATH
        run: echo "DATASET_PATH=dataset" >> $GITHUB_ENV

      # 8️⃣ パーサー実行
      - name: Run parser pipeline
        env:
          DATASET_PATH: dataset
        run: |
          python scripts/process_all.py

      # 9️⃣ dataset commit & push
      - name: Commit and Push dataset
        run: |
          cd dataset
          git config user.name "github-actions"
          git config user.email "actions@github.com"
          git add .
          # 変更が無い場合はcommitしない（エラー防止）
          if ! git diff --cached --quiet; then
            git commit -m "Auto update dataset $(date -u +'%Y-%m-%dT%H:%M:%SZ')"
            git push
          else
            echo "No changes to commit"
          fi
